import torch
import geopandas as gpd
from tqdm import tqdm
import os
import sys
import numpy as np

# è·¯å¾„å¤„ç†ï¼šç¡®ä¿èƒ½å¯¼å…¥åŒä¸€ç›®å½•ä¸‹çš„æ¨¡å—
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

try:
    from rooftop_dataset import RooftopDataset
    from train_classifier import get_model
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿ rooftop_dataset.py å’Œ train_classifier.py åœ¨ notebooks ç›®å½•ä¸‹")
    sys.exit(1)

def predict():
    # --- 1. é…ç½®è·¯å¾„ ---
    # å‡è®¾ä½ åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ (Leuven2030_Rooftops/)
    # æˆ–è€…åœ¨ notebooks ç›®å½•è¿è¡Œï¼Œè¿™é‡Œå°è¯•è‡ªåŠ¨é€‚é…
    
    # æ¨¡å‹è·¯å¾„ (åˆšåˆšè®­ç»ƒå¥½çš„)
    model_path = "notebooks/rooftop_classifier_resnet18.pth"
    if not os.path.exists(model_path):
        # å°è¯•å½“å‰ç›®å½•
        model_path = "rooftop_classifier_resnet18.pth"
    
    # æ•°æ®è·¯å¾„
    input_file = "notebooks/data/large_roofs_test.gpkg"
    if not os.path.exists(input_file):
        input_file = "data/large_roofs_test.gpkg" # å°è¯•ç›¸å¯¹è·¯å¾„
        
    # è¾“å‡ºè·¯å¾„ (ç”Ÿæˆçš„æ–°æ–‡ä»¶)
    output_file = input_file.replace(".gpkg", "_enriched.gpkg")

    # --- æ£€æŸ¥æ–‡ä»¶ ---
    if not os.path.exists(input_file):
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ•°æ®: {input_file}")
        return
    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {model_path}")
        return

    # --- 2. å‡†å¤‡è®¾å¤‡ ---
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if torch.backends.mps.is_available():
        device = torch.device("mps")
    print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {device}")

    # --- 3. åŠ è½½æ¨¡å‹ ---
    print(f"ğŸ§  åŠ è½½æ¨¡å‹: {model_path} ...")
    model = get_model(num_classes=2)
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.to(device)
    model.eval() # å¼€å¯è¯„ä¼°æ¨¡å¼

    # --- 4. åŠ è½½æ•°æ® ---
    print(f"ğŸ“‚ è¯»å–æ•°æ®: {input_file} ...")
    gdf = gpd.read_file(input_file)
    print(f"   å¾…å¤„ç†å±‹é¡¶æ•°: {len(gdf)}")

    # å‡†å¤‡æ•°æ®é›† (è‡ªåŠ¨ä¸‹è½½å›¾ç‰‡)
    dataset = RooftopDataset(gdf)
    
    # --- 5. å¼€å§‹æ¨ç† ---
    print("ğŸ”® å¼€å§‹ AI é¢„æµ‹...")
    predictions = []
    probabilities = []
    
    with torch.no_grad(): # ä¸è®¡ç®—æ¢¯åº¦ï¼Œçœå†…å­˜
        for i in tqdm(range(len(dataset))):
            try:
                img, _ = dataset[i] if dataset.labels is not None else (dataset[i], None)
                # dataset[i] è¿”å› (img) æˆ–è€… (img, label)ï¼Œè¿™é‡Œåšä¸ªå…¼å®¹å¤„ç†
                if isinstance(img, tuple): img = img[0]
                
                # å¢åŠ  batch ç»´åº¦
                img_input = img.unsqueeze(0).to(device)
                
                # é¢„æµ‹
                outputs = model(img_input)
                probs = torch.nn.functional.softmax(outputs, dim=1)
                conf, pred = torch.max(probs, 1)
                
                predictions.append(pred.item())
                probabilities.append(conf.item())
            except Exception as e:
                print(f"   âš ï¸ è·³è¿‡ç´¢å¼• {i}: {e}")
                predictions.append(0)
                probabilities.append(0.0)

    # --- 6. ä¿å­˜ç»“æœ ---
    print("ğŸ’¾ ä¿å­˜ç»“æœ...")
    label_map = {0: 'Flat', 1: 'Pitched'} # ç¡®ä¿è·Ÿè®­ç»ƒæ—¶ä¸€è‡´ï¼
    
    gdf['roof_type_id'] = predictions
    gdf['roof_type'] = [label_map[p] for p in predictions]
    gdf['ai_confidence'] = probabilities
    
    gdf.to_file(output_file, driver="GPKG")
    print(f"âœ… å®Œæˆï¼å·²ç”Ÿæˆå¢å¼ºæ•°æ®: {output_file}")
    print("ğŸ‘‰ ç°åœ¨å»åˆ·æ–°ä½ çš„ Streamlit ç½‘é¡µå§ï¼")

if __name__ == "__main__":
    predict()